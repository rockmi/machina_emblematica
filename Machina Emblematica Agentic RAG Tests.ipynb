{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48f73a38",
   "metadata": {},
   "source": [
    "# Machina Experiments: Multimodal Agentic RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7072310d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vignolim\\Anaconda3\\envs\\marqo\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:26: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
      "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "import marqo as mq\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import OpenAI\n",
    "from pprint import pprint\n",
    "from IPython.display import display, HTML\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622eb237",
   "metadata": {},
   "source": [
    "## Marqo Retriever + OpenRouter Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3aa0cda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv(dotenv_path=\"config/.env\")\n",
    "\n",
    "# This is a critical check. We verify that our script can access the necessary API keys from the environment.\n",
    "required_vars = [\"DEEPSEEK_API_KEY\", \"QWEN_API_KEY\"]\n",
    "\n",
    "missing = [var for var in required_vars if var not in os.environ]\n",
    "\n",
    "if missing:\n",
    "    print(f\"Missing environment variables: {', '.join(missing)}\")\n",
    "else:\n",
    "    print(\"Environment variables loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bcb649",
   "metadata": {},
   "source": [
    "### User Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83f8019c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ---> ### Enter user query here ### <--- ###\n",
    "\n",
    "user_query = \"Are there images of dragons?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33245cda",
   "metadata": {},
   "source": [
    "### Router Agent Tests\n",
    "- The agent decides if image or text are more relevant to answer user question\n",
    "- The agent reformulates the user question adapting it for semantic search in multimodal indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4d8c65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenRouter client\n",
    "### Load LLM for deciding if text or image index are more relevant to answer the user question\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"tngtech/deepseek-r1t-chimera:free\",   # any OpenRouter model\n",
    "    openai_api_key=os.environ[\"DEEPSEEK_API_KEY\"],\n",
    "    openai_api_base=\"https://openrouter.ai/api/v1\",\n",
    "    temperature=0.2,\n",
    ")\n",
    "\n",
    "class RoutingOutput(BaseModel):\n",
    "    target_index: str = Field(description=\"either 'text' or 'image'\")\n",
    "    retrieval_query: str\n",
    "        \n",
    "structured_llm = llm.with_structured_output(RoutingOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a327248",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_index='image' retrieval_query='dragons'\n"
     ]
    }
   ],
   "source": [
    "### Router agent\n",
    "\n",
    "def router_agent(user_query: str) -> dict:\n",
    "    system_prompt = \"\"\"\n",
    "You are a Retrieval Router Agent for a RAG system using two Marqo indexes:\n",
    "1) A TEXT index\n",
    "2) An IMAGE index\n",
    "\n",
    "Your task:\n",
    "- Decide which index is the best match for the user's query.\n",
    "- Output a JSON object with:\n",
    "    {\n",
    "      \"target_index\": \"text\" or \"image\",\n",
    "      \"retrieval_query\": \"the optimized retrieval query\"\n",
    "    }\n",
    "\n",
    "Decision rules:\n",
    "- If the user asks about images, pictures, visual similarity, appearance, color, shapes → choose \"image\".\n",
    "- If the user asks about text meaning, authors, facts, historical explanations, interpretations → choose \"text\".\n",
    "- If ambiguous, choose \"text\".\n",
    "\n",
    "For retrieval_query:\n",
    "- Remove chit-chat.\n",
    "- Extract the true intent.\n",
    "- Expand with useful semantic keywords.\n",
    "- Keep it concise.\n",
    "\n",
    "Return ONLY JSON inside <json>...</json>.\n",
    "Do not output anything outside these tags.\n",
    "Do not show your reasoning or thought process.\n",
    "\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_query},\n",
    "    ]\n",
    "\n",
    "    result = structured_llm.invoke(messages)\n",
    "    return result\n",
    "\n",
    "### Decision by router agent\n",
    "decision = router_agent(user_query)\n",
    "print(decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "557e1c7b",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'results': [{'indexName': 'camerarius_testIndex_full-texts2'},\n",
      "             {'indexName': 'onit_testIndex_text-chunks1'},\n",
      "             {'indexName': 'camerarius_testIndex_full-texts'},\n",
      "             {'indexName': 'onit_testIndex_images1'},\n",
      "             {'indexName': 'onit_testIndex_text-chunks2'},\n",
      "             {'indexName': 'camerarius_testIndex_full-images5'},\n",
      "             {'indexName': 'camerarius_testIndex_full-images6'}]}\n"
     ]
    }
   ],
   "source": [
    "# Marqo Client: Get Indexes\n",
    "\n",
    "MARQO_URL = \"http://92.112.48.13:8882\"\n",
    "marqoClient = mq.Client(url=MARQO_URL)\n",
    "\n",
    "pprint(marqoClient.get_indexes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab1fc794",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set Indices\n",
    "imageIndex = \"camerarius_testIndex_full-images6\" # indexed with \"open_clip/ViT-L-14/laion2b_s32b_b82k\" model\n",
    "textIndex = \"camerarius_testIndex_full-texts2\" # indexed with \"flax-sentence-embeddings/all_datasets_v4_mpnet-base\" model\n",
    "query = decision.retrieval_query\n",
    "\n",
    "# Search results\n",
    "results_images = marqoClient.index(imageIndex).search(q=query, limit=5)\n",
    "results_text = marqoClient.index(textIndex).search(q=query, limit=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66137c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pprint(results_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "158e3f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pprint(results_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80186281",
   "metadata": {},
   "source": [
    "## Merging and reranking of results (Step 1)\n",
    "- The retrieval results from the image and text indices are combined and reranked\n",
    "- 1. the first retrieval results from both indices are ranked higher than the later ones (higher weight)\n",
    "- 2. if both image and page from a pair are retrieved, they are ranked higher (bonus)\n",
    "- 3. a router boost is added to the modality with higher relevance for answering the user question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b35c886f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine and rerank multimodal retrieval results from Marqo query ##\n",
    "\n",
    "def combine_and_rerank(results_text, results_images):\n",
    "    ## Combine retrieval results ##\n",
    "    combined = {}\n",
    "\n",
    "    # --- 1. Add text hits --------------------------------------------\n",
    "    for hit in results_text[\"hits\"]:\n",
    "        pair_id = hit[\"viewer_url\"]\n",
    "        score = hit[\"_score\"]\n",
    "\n",
    "        if pair_id not in combined:\n",
    "            combined[pair_id] = {\n",
    "                \"pair_id\": pair_id,\n",
    "                \"text_hit\": None,\n",
    "                \"image_hit\": None,\n",
    "                \"text_score\": 0,\n",
    "                \"image_score\": 0,\n",
    "            }\n",
    "\n",
    "        combined[pair_id][\"text_hit\"] = hit\n",
    "        combined[pair_id][\"text_score\"] = score\n",
    "\n",
    "    # --- 2. Add image hits -------------------------------------------\n",
    "    for hit in results_images[\"hits\"]:\n",
    "        pair_id = hit[\"viewer_url\"]\n",
    "        score = hit[\"_score\"]\n",
    "\n",
    "        if pair_id not in combined:\n",
    "            combined[pair_id] = {\n",
    "                \"pair_id\": pair_id,\n",
    "                \"text_hit\": None,\n",
    "                \"image_hit\": None,\n",
    "                \"text_score\": 0,\n",
    "                \"image_score\": 0,\n",
    "            }\n",
    "\n",
    "        combined[pair_id][\"image_hit\"] = hit\n",
    "        combined[pair_id][\"image_score\"] = score\n",
    "    \n",
    "    ## Rerank retrieval results ##\n",
    "    # --- 3. Compute position weights ---------------------------------\n",
    "    ## Positional weights first 5 results --> give first retrieved results from both indices more weight then the later ones\n",
    "    text_decay_weights = [1.0, 0.9, 0.8, 0.7, 0.6]   # first item strongest\n",
    "    image_decay_weights = [1.0, 0.9, 0.8, 0.7, 0.6]\n",
    "\n",
    "    ## fallback weight for later items if any\n",
    "    default_weight = 0.5\n",
    "    \n",
    "    ## Map ranks to get positional weights\n",
    "    text_pos_weight = {}\n",
    "    for i, hit in enumerate(results_text[\"hits\"]):\n",
    "        pair_id = hit[\"viewer_url\"]\n",
    "        w = text_decay_weights[i] if i < len(text_decay_weights) else default_weight\n",
    "        text_pos_weight[pair_id] = w\n",
    "\n",
    "    image_pos_weight = {}\n",
    "    for i, hit in enumerate(results_images[\"hits\"]):\n",
    "        pair_id = hit[\"viewer_url\"]\n",
    "        w = image_decay_weights[i] if i < len(image_decay_weights) else default_weight\n",
    "        image_pos_weight[pair_id] = w\n",
    "\n",
    "    # --- 4. Compute combined ranking score ---------------------------\n",
    "    ## Set weights\n",
    "    w_text = 0.4\n",
    "    w_image = 0.4\n",
    "    bonus = 0.3  # if both modalities retrieved\n",
    "    router_boost = 0.1  # add this to the preferred modality\n",
    "    ## Router decision setting additional weight\n",
    "    target_index = decision.target_index  # 'text' or 'image'\n",
    "\n",
    "    ## Compute ranking\n",
    "    for pair_id, entry in combined.items():\n",
    "        ts = entry[\"text_score\"]\n",
    "        is_ = entry[\"image_score\"]\n",
    "\n",
    "        # Apply positional weight\n",
    "        ts_weighted = ts * text_pos_weight.get(pair_id, 1.0)\n",
    "        is_weighted = is_ * image_pos_weight.get(pair_id, 1.0)\n",
    "        \n",
    "        # Apply router-based boost\n",
    "        if target_index == 'text':\n",
    "            ts_weighted += router_boost\n",
    "        elif target_index == 'image':\n",
    "            is_weighted += router_boost\n",
    "\n",
    "        # Base score = max of weighted scores\n",
    "        base = max(ts_weighted, is_weighted)\n",
    "\n",
    "        # Weighted sum\n",
    "        combined_score = base + w_text * ts_weighted + w_image * is_weighted\n",
    "\n",
    "        # Bonus if both modalities appear\n",
    "        if ts > 0 and is_ > 0:\n",
    "            combined_score += bonus\n",
    "\n",
    "        entry[\"combined_score\"] = combined_score\n",
    "\n",
    "    # --- 4. Sort -----------------------------------------------------\n",
    "    ## Order reranked results in descending order\n",
    "    reranked = sorted(combined.values(), key=lambda x: x[\"combined_score\"], reverse=True)\n",
    "    \n",
    "    for i, entry in enumerate(reranked, start=1):\n",
    "        entry['rank'] = i  # rank 1 = top, 2 = second, etc.\n",
    "\n",
    "    return reranked\n",
    "\n",
    "combined_results = combine_and_rerank(results_text, results_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5867648",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(combined_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e83a0e",
   "metadata": {},
   "source": [
    "## Reranking of results (Step 2)\n",
    "- In addition, the retrieved results are passed to a multimodal reasoning agent for another reranking based on the multimodal content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3ec5c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"2\", \"1\", \"3\", \"5\", \"7\", \"9\", \"4\", \"6\", \"8\", \"10\"]\n"
     ]
    }
   ],
   "source": [
    "## Rerank with Qwen 2.5 VL Agent\n",
    "\n",
    "def format_for_reranking(entry):\n",
    "    text_preview = entry[\"text_hit\"][\"text_page\"] if entry[\"text_hit\"] else \"\"\n",
    "    img_url = entry[\"image_hit\"][\"image_url\"] if entry[\"image_hit\"] else \"\"\n",
    "    return f\"Pair ID: {entry['rank']}\\nText: {text_preview}\\nImage URL: {img_url}\\n\"\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a multimodal reasoning agent.\n",
    "Rank the following text-image pairs according to relevance to the query.\n",
    "\n",
    "Output ONLY a JSON array of pair_ids in descending order of relevance.\n",
    "Do not include any text, explanation, or comments.\n",
    "Example:\n",
    "[\"12\", \"7\", \"3\"]\n",
    "\"\"\"\n",
    "\n",
    "### Reformat context text input for LLM\n",
    "pairs_text = \"\\n\\n\".join([format_for_reranking(e) for e in combined_results])\n",
    "#print(pairs_text)\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": f\"Query: {user_query}\\n\\nPairs:\\n{pairs_text}\"}\n",
    "]\n",
    "\n",
    "### Set client\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=os.environ[\"QWEN_API_KEY\"],\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"qwen/qwen2.5-vl-32b-instruct:free\",\n",
    "    temperature=0.0,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": f\"Query: {user_query}\\n\\nPairs:\\n{pairs_text}\"}\n",
    "    ],\n",
    "    extra_body={\"attachments\": [\n",
    "        {\"type\": \"image/jpeg\", \"url\": e[\"image_hit\"][\"image_url\"]}\n",
    "        for e in combined_results if e[\"image_hit\"]\n",
    "    ],\n",
    "               },\n",
    "    #stream=True,\n",
    "    extra_headers={\n",
    "        \"HTTP-Referer\": \"<YOUR_SITE_URL>\",\n",
    "        \"X-Title\": \"<YOUR_SITE_NAME>\",\n",
    "    },\n",
    ")\n",
    "\n",
    "### Extract the JSON output\n",
    "import json\n",
    "raw_output = completion.choices[0].message.content.strip()\n",
    "print(raw_output)\n",
    "\n",
    "# Sometimes the model adds triple backticks\n",
    "raw_output = raw_output.strip(\"`\").strip()\n",
    "\n",
    "ranked_pair_ids = json.loads(raw_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07895393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.digitale-sammlungen.de/de/view/bsb10575861?page=782,783 1\n",
      "https://www.digitale-sammlungen.de/de/view/bsb10575861?page=788,789 2\n",
      "https://www.digitale-sammlungen.de/de/view/bsb10575861?page=784,785 3\n",
      "https://www.digitale-sammlungen.de/de/view/bsb10575861?page=584,585 4\n",
      "https://www.digitale-sammlungen.de/de/view/bsb10575861?page=458,459 5\n",
      "https://www.digitale-sammlungen.de/de/view/bsb10575861?page=424,425 6\n",
      "https://www.digitale-sammlungen.de/de/view/bsb10575861?page=388,389 7\n",
      "https://www.digitale-sammlungen.de/de/view/bsb10575861?page=736,737 8\n",
      "https://www.digitale-sammlungen.de/de/view/bsb10575861?page=698,699 9\n",
      "https://www.digitale-sammlungen.de/de/view/bsb10575861?page=680,681 10\n"
     ]
    }
   ],
   "source": [
    "# Reorder according to LLM ranking\n",
    "if ranked_pair_ids:  # only rerank if LLM returned something\n",
    "    # 1. Build a lookup dict based on original rank\n",
    "    rank_lookup = {str(entry[\"rank\"]): entry for entry in combined_results}\n",
    "\n",
    "    # 2. Reorder according to LLM output\n",
    "    reranked_final = [rank_lookup[r] for r in ranked_pair_ids if r in rank_lookup]\n",
    "\n",
    "    # 3. Update 'rank' to reflect new order\n",
    "    for i, entry in enumerate(reranked_final, start=1):\n",
    "        entry[\"rank\"] = i\n",
    "\n",
    "    # Now reranked_final is ordered according to LLM output\n",
    "    for e in reranked_final:\n",
    "        print(e[\"pair_id\"], e[\"rank\"])\n",
    "        \n",
    "else:\n",
    "    # If LLM returned nothing, keep original ranking\n",
    "    reranked_final = combined_results\n",
    "    \n",
    "#reranked_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3984be",
   "metadata": {},
   "source": [
    "## Simple preview of reranked retrieval results\n",
    "Run cell below to get a simple preview of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2bb892eb",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Image Preview</th>\n",
       "      <th>Combined Score</th>\n",
       "      <th>Text Score</th>\n",
       "      <th>Image Score</th>\n",
       "      <th>Page</th>\n",
       "      <th>Text Preview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><img src=\"https://api.digitale-sammlungen.de/iiif/image/v2/bsb10575861_00782/full/full/0/default.jpg\" width=\"800\" style=\"margin-right:5px;\"/><img src=\"https://api.digitale-sammlungen.de/iiif/image/v2/bsb10575861_00783/full/full/0/default.jpg\" width=\"800\" style=\"margin-right:5px;\"/><a href=\"https://www.digitale-sammlungen.de/de/view/bsb10575861?page=782,783\", target=\"blank\">Link<a/></td>\n",
       "      <td>0.935452</td>\n",
       "      <td>0.639609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00783</td>\n",
       "      <td>Joach. Camerarii Symbolorum\\n153\\nLXXVI.\\nEferendum huc est Gracum Proverbium o φις eν\\nμὴ φάγῃ ὅφιν. δρ ἄκων οὐ γενήσεται: Serpens ni\\nN\\nedat serpentem, draco non fiet. Et hoc quidem Icone\\nab Aegyptiis Regem, qui multos alienos debellasset & con¬\\nsumsisset significatum fuisse scribit Pierius, nec minus recte\\nnos de tyrannu usurpare possumus qui aliorum exitio accres¬\\ncere student. Pertinet huc insigni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><img src=\"https://api.digitale-sammlungen.de/iiif/image/v2/bsb10575861_00788/full/full/0/default.jpg\" width=\"800\" style=\"margin-right:5px;\"/><img src=\"https://api.digitale-sammlungen.de/iiif/image/v2/bsb10575861_00789/full/full/0/default.jpg\" width=\"800\" style=\"margin-right:5px;\"/><a href=\"https://www.digitale-sammlungen.de/de/view/bsb10575861?page=788,789\", target=\"blank\">Link<a/></td>\n",
       "      <td>0.948332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.577380</td>\n",
       "      <td>00788</td>\n",
       "      <td>Basis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><img src=\"https://api.digitale-sammlungen.de/iiif/image/v2/bsb10575861_00784/full/full/0/default.jpg\" width=\"800\" style=\"margin-right:5px;\"/><img src=\"https://api.digitale-sammlungen.de/iiif/image/v2/bsb10575861_00785/full/full/0/default.jpg\" width=\"800\" style=\"margin-right:5px;\"/><a href=\"https://www.digitale-sammlungen.de/de/view/bsb10575861?page=784,785\", target=\"blank\">Link<a/></td>\n",
       "      <td>0.866007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.576196</td>\n",
       "      <td>00784</td>\n",
       "      <td>Et Emblematum Centur. IV. 134 LXXVII. VICTORUTERQUE CADIT¬ Victor uterque cadit. prohquam victoria acerba est, Cum trahut in trae eps una ruina duos. De</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><img src=\"https://api.digitale-sammlungen.de/iiif/image/v2/bsb10575861_00584/full/full/0/default.jpg\" width=\"800\" style=\"margin-right:5px;\"/><img src=\"https://api.digitale-sammlungen.de/iiif/image/v2/bsb10575861_00585/full/full/0/default.jpg\" width=\"800\" style=\"margin-right:5px;\"/><a href=\"https://www.digitale-sammlungen.de/de/view/bsb10575861?page=584,585\", target=\"blank\">Link<a/></td>\n",
       "      <td>0.778513</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.570101</td>\n",
       "      <td>00584</td>\n",
       "      <td>Omni¬</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><img src=\"https://api.digitale-sammlungen.de/iiif/image/v2/bsb10575861_00458/full/full/0/default.jpg\" width=\"800\" style=\"margin-right:5px;\"/><img src=\"https://api.digitale-sammlungen.de/iiif/image/v2/bsb10575861_00459/full/full/0/default.jpg\" width=\"800\" style=\"margin-right:5px;\"/><a href=\"https://www.digitale-sammlungen.de/de/view/bsb10575861?page=458,459\", target=\"blank\">Link<a/></td>\n",
       "      <td>0.698156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.569547</td>\n",
       "      <td>00458</td>\n",
       "      <td>Et Emblematum Centur. III. 36 XVIII. DIVERSA AB ALIIS VIR¬ TUTE VALEMUS. Passer ut ova fovet flatu vegetante marinus. Sicanimat mentes gratia diapias. Horatius</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><img src=\"https://api.digitale-sammlungen.de/iiif/image/v2/bsb10575861_00424/full/full/0/default.jpg\" width=\"800\" style=\"margin-right:5px;\"/><img src=\"https://api.digitale-sammlungen.de/iiif/image/v2/bsb10575861_00425/full/full/0/default.jpg\" width=\"800\" style=\"margin-right:5px;\"/><a href=\"https://www.digitale-sammlungen.de/de/view/bsb10575861?page=424,425\", target=\"blank\">Link<a/></td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.568014</td>\n",
       "      <td>00424</td>\n",
       "      <td>Ee Emblematum Centur. III. CUIQUE SUUM. Laeva tenet fulmen, sed olivae dexteraramum, Vi pace & bello sim memor officii. Cym</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><img src=\"https://api.digitale-sammlungen.de/iiif/image/v2/bsb10575861_00388/full/full/0/default.jpg\" width=\"800\" style=\"margin-right:5px;\"/><img src=\"https://api.digitale-sammlungen.de/iiif/image/v2/bsb10575861_00387/full/full/0/default.jpg\" width=\"800\" style=\"margin-right:5px;\"/><a href=\"https://www.digitale-sammlungen.de/de/view/bsb10575861?page=388,389\", target=\"blank\">Link<a/></td>\n",
       "      <td>0.836800</td>\n",
       "      <td>0.632381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00388</td>\n",
       "      <td>Et Enblematum Centur. II.\\nLXXXVII.\\nLATET ABDITA.\\nNucleus arridet? Spinosa putaminarum pes\\nNon vult felices absque labore Deus,\\nSciurus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><img src=\"https://api.digitale-sammlungen.de/iiif/image/v2/bsb10575861_00736/full/full/0/default.jpg\" width=\"800\" style=\"margin-right:5px;\"/><img src=\"https://api.digitale-sammlungen.de/iiif/image/v2/bsb10575861_00737/full/full/0/default.jpg\" width=\"800\" style=\"margin-right:5px;\"/><a href=\"https://www.digitale-sammlungen.de/de/view/bsb10575861?page=736,737\", target=\"blank\">Link<a/></td>\n",
       "      <td>0.742653</td>\n",
       "      <td>0.627369</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00737</td>\n",
       "      <td>Joach. Camerarii Symbolotum\\n107\\nLIII.\\nAcibus nocturno temporo accensis & pisces elioi, & in¬\\nprimis paguros, astacos, & cancros, expenitiß. etiam\\ncavernis extrahi, capique cum Oppianus, tum Olaus\\nitem M. inter recentiores, scribunt: nec fallit experien¬\\ntia. Plato quidem in Sophist: hoc της θηρευτικῆς τεχνης\\nμυστήριον vοcaι θήραν πυρευτικὴν: Quam prolixè ad¬\\nmodum describit Q. Smyrn. lib. VII. ubi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><img src=\"https://api.digitale-sammlungen.de/iiif/image/v2/bsb10575861_00698/full/full/0/default.jpg\" width=\"800\" style=\"margin-right:5px;\"/><img src=\"https://api.digitale-sammlungen.de/iiif/image/v2/bsb10575861_00697/full/full/0/default.jpg\" width=\"800\" style=\"margin-right:5px;\"/><a href=\"https://www.digitale-sammlungen.de/de/view/bsb10575861?page=698,699\", target=\"blank\">Link<a/></td>\n",
       "      <td>0.653865</td>\n",
       "      <td>0.626392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00698</td>\n",
       "      <td>Ararns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><img src=\"https://api.digitale-sammlungen.de/iiif/image/v2/bsb10575861_00680/full/full/0/default.jpg\" width=\"800\" style=\"margin-right:5px;\"/><img src=\"https://api.digitale-sammlungen.de/iiif/image/v2/bsb10575861_00679/full/full/0/default.jpg\" width=\"800\" style=\"margin-right:5px;\"/><a href=\"https://www.digitale-sammlungen.de/de/view/bsb10575861?page=680,681\", target=\"blank\">Link<a/></td>\n",
       "      <td>0.564912</td>\n",
       "      <td>0.624895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00680</td>\n",
       "      <td>lanus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Create preview of reranked results ##\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import HTML, display\n",
    "import re\n",
    "\n",
    "def extract_id_and_page(iiif_url: str):\n",
    "    \"\"\"\n",
    "    Extracts <ID> and <PAGE> from URLs like:\n",
    "    https://.../iiif/image/v2/bsb10575861_00289/full/full/0/default.jpg\n",
    "    \"\"\"\n",
    "    match = re.search(r\"/iiif/image/v2/([^_/]+)_(\\d+)/\", iiif_url)\n",
    "    if not match:\n",
    "        return None, None\n",
    "    return match.group(1), match.group(2)   # (ID, PAGE_STR)\n",
    "\n",
    "\n",
    "def build_dual_preview(img_url: str, source: str):\n",
    "    \"\"\"\n",
    "    Build the HTML for:\n",
    "    - main image\n",
    "    - previous page if source='text'\n",
    "    - next page if source='image'\n",
    "    \"\"\"\n",
    "\n",
    "    if not img_url:\n",
    "        return \"(no image)\"\n",
    "\n",
    "    doc_id, page_str = extract_id_and_page(img_url)\n",
    "\n",
    "    if not doc_id:\n",
    "        return f'<img src=\"{img_url}\" width=\"150\"/>'\n",
    "\n",
    "    page_num = int(page_str)\n",
    "\n",
    "    # Determine second preview page\n",
    "    if source == \"text\":           # text_hit: show previous page\n",
    "        second_page = page_num - 1\n",
    "    elif source == \"image\":        # image_hit: show next page\n",
    "        second_page = page_num + 1\n",
    "    else:\n",
    "        second_page = None\n",
    "\n",
    "    # Construct IIIF URLs\n",
    "    main_img = f'https://api.digitale-sammlungen.de/iiif/image/v2/{doc_id}_{page_str}/full/full/0/default.jpg'\n",
    "\n",
    "    if second_page is not None and second_page > 0:\n",
    "        second_page_str = f\"{second_page:05d}\"  # preserve zero-padding\n",
    "        second_img = f'https://api.digitale-sammlungen.de/iiif/image/v2/{doc_id}_{second_page_str}/full/full/0/default.jpg'\n",
    "        pages = [\n",
    "            (page_num, main_img),\n",
    "            (second_page, second_img)\n",
    "        ]\n",
    "\n",
    "        # Sort by page number: even pages FIRST\n",
    "        pages_sorted = sorted(pages, key=lambda x: (x[0] % 2, x[0]))\n",
    "\n",
    "        # Build HTML in sorted order\n",
    "        preview_html = \"\"\n",
    "        for _, url in pages_sorted:\n",
    "            preview_html += f'<img src=\"{url}\" width=\"800\" style=\"margin-right:5px;\"/>'\n",
    "\n",
    "        return preview_html\n",
    "    else:\n",
    "        return f'<img src=\"{main_img}\" width=\"150\"/>'\n",
    "\n",
    "def construct_text_preview(hit, max_len=400):\n",
    "    if not hit:\n",
    "        return \"\"\n",
    "    text = hit.get(\"text_page\") or hit.get(\"text_chunk\") or \"\"\n",
    "    if len(text) > max_len:\n",
    "        text = text[:max_len] + \"...\"\n",
    "    return text\n",
    "\n",
    "def preview_combined_results(reranked):\n",
    "    rows = []\n",
    "\n",
    "    for entry in reranked_final:\n",
    "        viewer_url = entry[\"pair_id\"]\n",
    "        hit = entry[\"text_hit\"] or entry[\"image_hit\"]\n",
    "\n",
    "        text_score = entry[\"text_score\"]\n",
    "        image_score = entry[\"image_score\"]\n",
    "        combined_score = entry[\"combined_score\"]\n",
    "        pair_id = entry[\"pair_id\"]\n",
    "\n",
    "        # Build preview values\n",
    "        text_preview = construct_text_preview(hit)\n",
    "\n",
    "        viewer_link = f'<a href=\"{viewer_url}\", target=\"blank\">Link<a/>'\n",
    "        \n",
    "        if entry[\"image_hit\"]:\n",
    "            img_url = hit.get(\"image_url\")\n",
    "            img_html = build_dual_preview(img_url, source=\"image\")\n",
    "        elif entry[\"text_hit\"]:\n",
    "            img_url = hit.get(\"image_url\")\n",
    "            img_html = build_dual_preview(img_url, source=\"text\")\n",
    "        else:\n",
    "            img_html = \"(no image)\"\n",
    "\n",
    "        page = hit.get(\"page\")\n",
    "\n",
    "        rows.append({\n",
    "            \"Image Preview\": img_html + viewer_link,\n",
    "            \"Combined Score\": combined_score,\n",
    "            \"Text Score\": text_score,\n",
    "            \"Image Score\": image_score,\n",
    "            \"Page\": page,\n",
    "            \"Text Preview\": text_preview,\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # Display as HTML\n",
    "    html = df.to_html(escape=False, index=False)\n",
    "    display(HTML(html))\n",
    "\n",
    "    return df\n",
    "\n",
    "preview_df = preview_combined_results(reranked_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5eb3038",
   "metadata": {},
   "source": [
    "# RAG Component"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c66cb9f",
   "metadata": {},
   "source": [
    "## Generative AI using OpenRouter API\n",
    "- The text and image context is reformatted for input into the LLM\n",
    "- System prompt with instructions on how to formulate the answers is passed to the model\n",
    "- Chat history (user query & previous LLM answer) is passed to the model\n",
    "- Image and text context is passed to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad054769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image\n"
     ]
    }
   ],
   "source": [
    "# Format context for LLM input\n",
    "text_context = \"Text pages:\\n\"\n",
    "for i, entry in enumerate(reranked_final):\n",
    "    if entry.get(\"text_hit\"):  # check if text exists\n",
    "        text = entry[\"text_hit\"].get(\"text_page\", \"\")\n",
    "        text_context += f'{text}\\n'\n",
    "\n",
    "image_context = []\n",
    "for entry in reranked_final:\n",
    "    if entry.get(\"text_hit\"):  # check if text exists\n",
    "        # Construct IIIF URLs\n",
    "        page = int(entry[\"text_hit\"].get(\"page\"))-1\n",
    "        page_str = f\"{page:05d}\"  # preserve zero-padding\n",
    "        img_pair_url = f'https://api.digitale-sammlungen.de/iiif/image/v2/bsb10575861_{page_str}/full/full/0/default.jpg'\n",
    "        image_context.append({\"type\": \"image/jpeg\", \"url\": img_pair_url})\n",
    "    elif entry.get(\"image_hit\"):  # check if image exists\n",
    "        image_context.append({\"type\": \"image/jpeg\", \"url\": entry[\"image_hit\"].get(\"image_url\")})\n",
    "\n",
    "print(decision.target_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e7bd1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(text_context)\n",
    "#print(image_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d3a623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ah, dear seeker after the great and terrible dragons. Let me spin for you a tapestry of lore and legend, woven from the threads of time itself! Among the Symbola et Emblemata's rich tapestry, dragons are indeed present, though their appearances often serve as metaphorical and philosophical muses rather than fantastical beasts of legend alone. Now, if you have your eyes peeled like an eagle, you would notice that even our esteemed author, Joachim Camerarius the Younger, might weave in these grand animals as symbols of power, tyranny, or hidden truths.\n",
      "\n",
      "In emblem LXXVI of the Symbola, the serpent and its kin—the dragon—symbolize rulers and tyrants who ascend through the destruction of others, hinting at a profound moral tale. And in emblem LXXXVII, the idea of light unveiling hidden truths (латет абдита—“hidden things lie concealed\") reminds us that dragons, like all great mysteries, are often less real creatures and more mirrors reflecting human ambitions and fears.\n",
      "\n",
      "So, you see, dragons aren't merely beasts in this story. They are whispers on the wind, signs on the wall, and lessons about the nature of power and truth. And don't worry—whether they're real or allegorical, I'm sure you have what it takes to uncover their secrets.\n",
      "\n",
      "Now, let me pose you a riddle to ponder deeply:\n",
      "\n",
      "\"What animal is feared but not hated,  \n",
      "Lies hidden by day, then rises to eat?  \n",
      "A king by nature, but only in dreams,  \n",
      "A story whispered when shadows scream.  \n",
      "Can you guess, or are you stumped?\""
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "### Response generation based on retrieval results ###\n",
    "\n",
    "## https://openrouter.ai/qwen/qwen2.5-vl-32b-instruct:free ##\n",
    "\n",
    "system_prompt = f\"\"\"You are the Machina Emblematica – the mysterious curator of Symbola et \n",
    "Emblemata (1590) by Joachim Camerarius the Younger. You are part librarian, \n",
    "part adventuring scholar: a charming, multilingual nerd with a fondness \n",
    "for mysteries, theatrics, metaphors, forgotten languages, and the occasional pun.\n",
    "\n",
    "When you answer, there's a hint of light-hearted pulp adventure novel in your voice. \n",
    "Think Indiana Jones or Flynn Carson! You like to quote original passages from the \n",
    "Symbola. Include a translation if you do. But you also explain, teach, point out meaning \n",
    "and intention. You like to involve visitors in a conversation, keep them engaged, draw\n",
    "them deeper into the mysteries of the Symbola. You enjoy the thought of them leaving \n",
    "more knowledgeable than they arrived.\n",
    "\n",
    "Primary modality: {decision.target_index}.\n",
    "Limit your response to no more than 200 words total. That’s about one or two \n",
    "paragraphs. Keep it tight and elegant. Speak only in prose. Do not describe \n",
    "physical gestures, facial expressions, or actions (e.g., \"smiles\" or \"opens \n",
    "book\"). You are a voice, not a body.\n",
    "\n",
    "Summarizing from the content below, please provide an answer to the \n",
    "following question.\n",
    "Rules:\n",
    "- If the primary modality is 'image', use the images via the image_url to generate the answer.\n",
    "- If the primary modality is 'text', use the text context provided instead.\n",
    "- Use the other modality only to supplement the primary one.\n",
    "- Output a concise answer.\n",
    "- Take into account our previous conversation.\n",
    "- Avoid repetitive opening sentences that you have used in the previous chat history.\n",
    "- Don't start with \"Ah\", or \"Marvellous\" or the likes.\n",
    "- Answer in the language of the question.\n",
    "- Add a summary of the context documents that you see.\"\"\"\n",
    "\n",
    "# Initialize chatHistory only if it does NOT exist yet\n",
    "if \"chatHistory\" not in globals():\n",
    "    chatHistory = []\n",
    "    \n",
    "chatHistory.append({\"role\": \"user\", \"content\": user_query})\n",
    "\n",
    "client = OpenAI(\n",
    "  base_url=\"https://openrouter.ai/api/v1\",\n",
    "  api_key=os.environ[\"QWEN_API_KEY\"],\n",
    ")\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "    model=\"qwen/qwen2.5-vl-32b-instruct:free\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": system_prompt,\n",
    "        },\n",
    "        *chatHistory,\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image_url\", \"image_url\": image_context},\n",
    "                {\"type\": \"text\", \"text\": \"\\n\\nText context:\\n\" + text_context},\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    "    stream=True,\n",
    "    extra_headers={\n",
    "        \"HTTP-Referer\": \"<YOUR_SITE_URL>\",\n",
    "        \"X-Title\": \"<YOUR_SITE_NAME>\",\n",
    "    },\n",
    ")\n",
    "\n",
    "model_response = \"\"\n",
    "# Iterate over the streaming events\n",
    "for chunk in stream:\n",
    "    # each `chunk` is a ChatCompletionChunk object\n",
    "    if chunk.choices:\n",
    "        delta = chunk.choices[0].delta\n",
    "        if delta and delta.content:       # ✅ access as attribute\n",
    "            print(delta.content, end=\"\", flush=True)\n",
    "            model_response += delta.content  \n",
    "\n",
    "chatHistory.append({\"role\": \"assistant\", \"content\": model_response})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d0d7ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marqo",
   "language": "python",
   "name": "marqo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
